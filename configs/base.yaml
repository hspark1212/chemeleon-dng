task: "csp" # "csp", "dng", "guide", "clip"
random_seed: 42
sweep: False
load_path: null # load pre-trained model
resume_from: null # resume from checkpoint

logger:
  project: Chemeleon-RL-v0.0.1
  name: Chemeleon-RL
  offline: False
  save_dir: ./logs
  log_model: True
  group: null

datamodule:
  data_dir: data/mp-20
  dataset_type: mp_20
  target_condition: null
  batch_size: 256
  num_workers: 8
  pin_memory: True

model:
  hidden_dim: 512
  time_dim: 256
  num_layers: 6
  max_atoms: 100
  act_fn: silu
  dis_emb: sin
  num_freqs: 128
  ln: True
  ip: True
  smooth: False
  cond_dim: 0
  pred_atom_types: False

optimizer:
  optimizer: "adam" # "adam", "adamw", "sgd"
  lr: 0.001
  weight_decay: 0
  scheduler: "reduce_on_plateau" # "constant", "cosine", "reduce_on_plateau", "linear_decay", "warmup_linear"
  patience: 30 # patience for reduce_on_plateau scheduler
  early_stopping: 500 # patience for early stopping
  warmup_steps: 0

trainer:
  num_nodes: 1
  devices: 1
  accelerator: gpu
  max_epochs: 1500
  deterministic: False
  gradient_clip_val: 0.5 # null for no clipping
  gradient_clip_algorithm: value
  check_val_every_n_epoch: 5
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0

evaluation:
  cond_scale: 2.0
